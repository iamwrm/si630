{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:24:29.333182Z",
     "start_time": "2020-04-29T21:24:29.153011Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:24:31.436929Z",
     "start_time": "2020-04-29T21:24:30.825720Z"
    }
   },
   "outputs": [],
   "source": [
    "tw_pd = pd.read_csv(\"cna.csv\",sep=',',encoding='utf-8',names=['weibo_id','time','id_name','text','ul','ul2','class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:24:53.132421Z",
     "start_time": "2020-04-29T21:24:53.110119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'情感倾向': 1,\n",
       "         '0': 57619,\n",
       "         '-1': 16902,\n",
       "         '1': 25392,\n",
       "         '-': 1,\n",
       "         '4': 1,\n",
       "         '-2': 1,\n",
       "         nan: 81,\n",
       "         '·': 1,\n",
       "         '10': 1,\n",
       "         '9': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(tw_pd['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:39.242935Z",
     "start_time": "2020-04-28T19:53:39.237422Z"
    }
   },
   "outputs": [],
   "source": [
    "train_S = tw_pd['class'].iloc[1:]\n",
    "train_ST = tw_pd['text'].iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:39.251061Z",
     "start_time": "2020-04-28T19:53:39.244604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。带着一丝迷信，早...\n",
       "2           开年大模型…累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼#Luna的Krystallife#?\n",
       "3         �偳癯空饩褪俏业�，爹，发烧快好，毕竟美好的假期拿来养病不太好，假期还是要好好享受快乐，爹，...\n",
       "4                            新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的?\n",
       "5         问：我们意念里有坏的想法了，天神就会给记下来，那如果有好的想法也会被记下来吗？答：那当然了。...\n",
       "                                ...                        \n",
       "99996     #抗击新型肺炎第一线#【@中国计量大学研制新冠病毒蛋白标准样品】记者从中国计量大学获悉，新型...\n",
       "99997     1、类RaTG13病毒（一种从云南蝙蝠身上分离出来的冠状病毒）可能是2019-nCoV的源头...\n",
       "99998     #微博辟谣#没有证据表明，吃大蒜、漱口水、涂抹芝麻油、生理盐水洗鼻子等手段可以防止感染新型冠...\n",
       "99999     【新冠疫情最受关注的十一篇英文核心期刊论文全解析】本文整理了关于新型冠状病毒最受关注的十一篇...\n",
       "100000    从蝙蝠携带的冠状病毒变异成2019-nCoV冠状病毒,怎样才能发生变异呢？有两种可能1.自然...\n",
       "Name: text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:39.255593Z",
     "start_time": "2020-04-28T19:53:39.252899Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:39.923364Z",
     "start_time": "2020-04-28T19:53:39.258346Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import jieba\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = jieba.cut(text)\n",
    "    text=  ' '.join(text)\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:40.567221Z",
     "start_time": "2020-04-28T19:53:39.925146Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??//@朴素善xi:是的，冷暖自知//@·飛行島嶼·:他们年少相识一起成长一起出道互相照顾经历了我看不到的岁月和曲折发烧感冒不是你第一时间知道快乐喜悦不是和你第一时间分享我算什么你又算什么有什么资格去点评他们的感情\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.629 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    朴 素   善   x i       是   的       冷 暖 自 知       飛 行   島 嶼       他 们   年 少   相 识   一 起   成 长   一 起   出   道   互 相 照 顾   经 历   了   我   看 不 到   的   岁 月   和   曲 折   发 烧   感 冒   不 是   你   第 一   时 间   知 道   快 乐   喜 悦   不 是   和   你   第 一   时 间   分 享   我 算   什 么   你   又   算   什 么   有   什 么   资 格   去   点 评   他 们   的   感 情    \n"
     ]
    }
   ],
   "source": [
    "print(train_ST[20])\n",
    "\n",
    "text_line =train_ST[20]\n",
    "\n",
    "text_line = preprocessor(text_line)\n",
    "\n",
    "seg_list = tokenizer(text_line)\n",
    "\n",
    "\n",
    "print(' '.join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:40.574730Z",
     "start_time": "2020-04-28T19:53:40.568892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         写在年末冬初孩子流感的第五天，我们仍然没有忘记热情拥抱这2020年的第一天。带着一丝迷信，早...\n",
       "2           开年大模型…累到以为自己发烧了腰疼膝盖疼腿疼胳膊疼脖子疼#Luna的Krystallife#?\n",
       "3         �偳癯空饩褪俏业�，爹，发烧快好，毕竟美好的假期拿来养病不太好，假期还是要好好享受快乐，爹，...\n",
       "4                            新年的第一天感冒又发烧的也太衰了但是我要想着明天一定会好的?\n",
       "5         问：我们意念里有坏的想法了，天神就会给记下来，那如果有好的想法也会被记下来吗？答：那当然了。...\n",
       "                                ...                        \n",
       "99996     #抗击新型肺炎第一线#【@中国计量大学研制新冠病毒蛋白标准样品】记者从中国计量大学获悉，新型...\n",
       "99997     1、类RaTG13病毒（一种从云南蝙蝠身上分离出来的冠状病毒）可能是2019-nCoV的源头...\n",
       "99998     #微博辟谣#没有证据表明，吃大蒜、漱口水、涂抹芝麻油、生理盐水洗鼻子等手段可以防止感染新型冠...\n",
       "99999     【新冠疫情最受关注的十一篇英文核心期刊论文全解析】本文整理了关于新型冠状病毒最受关注的十一篇...\n",
       "100000    从蝙蝠携带的冠状病毒变异成2019-nCoV冠状病毒,怎样才能发生变异呢？有两种可能1.自然...\n",
       "Name: text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:40.584453Z",
     "start_time": "2020-04-28T19:53:40.576632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          0\n",
       "2         -1\n",
       "3          1\n",
       "4          1\n",
       "5          1\n",
       "          ..\n",
       "99996      0\n",
       "99997      0\n",
       "99998      0\n",
       "99999      1\n",
       "100000     0\n",
       "Name: class, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:40.626085Z",
     "start_time": "2020-04-28T19:53:40.586273Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_ST\n",
    "y = train_S\n",
    "\n",
    "X.fillna(method = 'ffill', inplace = True)\n",
    "y.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:53:40.629936Z",
     "start_time": "2020-04-28T19:53:40.627742Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # split the dataset in train and test\n",
    "# X = train_ST\n",
    "# y = train_S\n",
    "\n",
    "# # X.fillna(method = 'ffill', inplace = True)\n",
    "# # y.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T19:54:05.665878Z",
     "start_time": "2020-04-28T19:54:05.646175Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__tokenizer': [tokenizer],\n",
    "               'vect__preprocessor': [ preprocessor],\n",
    "               'clf__penalty': ['l2'],\n",
    "               'clf__C': [1.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__tokenizer': [tokenizer],\n",
    "               'vect__preprocessor': [ preprocessor],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l2'],\n",
    "               'clf__C': [1.0]},\n",
    "              ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T20:00:24.834733Z",
     "start_time": "2020-04-28T19:54:09.362970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  3.3min remaining:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.0min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__C': 1.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__preprocessor': <function preprocessor at 0x7f7d6b224830>, 'vect__tokenizer': <function tokenizer at 0x7f7d6b224200>}\n",
      "Best accuracy: 0.718\n",
      "Accuracy in test: 0.716\n"
     ]
    }
   ],
   "source": [
    "gs_lr_tfidf.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameter set: ' + str(gs_lr_tfidf.best_params_))\n",
    "print('Best accuracy: %.3f' % gs_lr_tfidf.best_score_)\n",
    "\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Accuracy in test: %.3f' % clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
